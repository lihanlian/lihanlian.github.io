---
title: "From Control Hamiltonian to Algebraic Riccati Equation and Pontryagin's Maximum Principle"
date: 2024-07-16
permalink: /posts/2024/07/16
tags:
  - Algebraic Riccati Equation
  - Linear Qudratic Regulator
  - Calculus of Variations
---
Inspired by the Hamiltonian of classical mechanics, Lev Pontryagin introduced the [_Control Hamiltonian_](https://en.wikipedia.org/wiki/Hamiltonian_(control_theory)) and formulated his celebrated [_Pontragin's Maximum Principle (PMP)_](https://en.wikipedia.org/wiki/Pontryagin%27s_maximum_principle). This blog will first discuss general cases of optimal control problems, including scenarios with both free final time and final states. Then, the derivation of [_Algebraic Riccati Equation (ARE)_](https://en.wikipedia.org/wiki/Algebraic_Riccati_equation) in the context of **_Continuous Linear Qudratic Regulator (LQR)_** from the perspective of the **_Control Hamiltonian_** will be introduced. It will then explain the **_PMP_**, finally followed by the example problem of **_Constrained Continous LQR_**.

## More general senarios of optimal control problems

Consider the following simple robot dynamics (single-integrator model) and the objetive functional aimed to minimize:

$$ J = \frac{1}{2} \int_{0}^{1} (x^2 + u^2) \, dt $$

$$ s.t. \dot{x} = u(t)$$

This is also in [one of the previous blogs](https://lihanlian.github.io/posts/2024/06/30) on Euler-Lagrange Equation, and it's the second example but is a fixed final state and fixed final time problem (\\(x(0) = 0, x(1) = 10,\\)). In this blog, Let's take a look at more general cases including free final state and/or free final time. However, before directly solves the problem, I want to shows the process of derivation common solution strategries for different secaniros using calculus of variations.



**- Fixed final state with free final time**

**- Free final state with fixed final time**

**- Free final state with free final time**

## Continuous LQR and ARE

It turns out that the Algebraic Riccati Equation can be derived using PMP.

$$ J = \frac{1}{2} \int_{0}^{T} (x(t)'Qx(t) + u(t)'Ru(t)) \, dt $$
 
$$ s.t. \dot{x} = Ax(t) + Bu(t) $$

### - Formulate Control Hamiltonian:

$$ H(x, u, \lambda, t) = \frac{1}{2} (x'Qx + u'Ru) + \lambda' (Ax + Bu) $$

### - Construsct co-state Equations:

$$ \dot{\lambda} = -\frac{\partial H}{\partial x} $$

$$ \frac{\partial H}{\partial x} = Qx + A'\lambda $$

$$ \dot{\lambda} = -Qx - A'\lambda $$

### - Obtaining Optimal \\( u \\):

Since we are __NOT__ concerned with the control input constraints here, the optimal control input \\(u\\) can be directly obtained by setting the paritial derivatives to be zero.

$$ \frac{\partial H}{\partial u} = Ru + B'\lambda = 0, \quad  u = -R^{-1}B'\lambda$$

### - Substitute optimal \\( u \\) into state space equation:

$$ \dot{x} = Ax + B(-R^{-1}B'\lambda) = Ax - BR^{-1}B'\lambda $$

### - Riccati Equation:

Suppose \\( \lambda = Px \\), then \\( \dot{\lambda} = \dot{P}x + Px \\), substitute into co-state equation: 

$$ \dot{\lambda} = \dot{P}x + P(Ax - BR^{-1}B'Px) = -Qx - A'Px $$

$$ \dot{P}x + PAx - PBR^{-1}B'Px = -Qx - A'Px $$

$$ \dot{P} + PA + A'P - PBR^{-1}B'P + Q = 0 $$

## Pontryagin's Maximum Principle

**- Continuous time PMP**

Consider an n-dimensional dynamical system, with state variable \( x \in \mathbb{R}^n \), and control variable \( u \in \mathbb{U} \), where \(\mathbb{U}\) is the set of admissible controls. The evolution of the system is determined by the state and the control, according to the differential equation

$$ \dot{x} = f(x, u).$$

Let the system's initial state be \\( x_0 \\) and let the system's evolution be controlled over the time period with values \\( t \in [0, T] \\). The latter is determined by the following differential equation:
\[
\dot{x} = f(x, u), \quad x(0) = x_0, \quad u(t) \in \mathbb{U}, \quad t \in [0, T].
\]
The control trajectory \( u : [0, T] \to \mathbb{U} \) is to be chosen according to an objective. The objective is a functional \( J \) defined by
\[
J = \Psi(x(T)) + \int_{0}^{T} L(x(t), u(t)) \, dt,
\]
where \( L(x, u) \) can be interpreted as the rate of cost for exerting control \( u \) in state \( x \), and \( \Psi(x) \) can be interpreted as the cost for ending up at state \( x \). The specific choice of \( L \), \( \Psi \) depends on the application.

The constraints on the system dynamics can be adjoined to the Lagrangian \( L \) by introducing time-varying Lagrange multiplier vector \( \lambda \), whose elements are called the costates of the system. This motivates the construction of the Hamiltonian \( H \) defined for all \( t \in [0, T] \) by:
\[
H(x(t), u(t), \lambda(t), t) = \lambda^T(t) \cdot f(x(t), u(t)) + L(x(t), u(t)),
\]
where \( \lambda^T \) is the transpose of \( \lambda \).

Pontryagin's minimum principle states that the optimal state trajectory \( x^* \), optimal control \( u^* \), and corresponding Lagrange multiplier vector \( \lambda^* \) must minimize the Hamiltonian \( H \) so that
\[
H(x^*(t), u^*(t), \lambda^*(t), t) \leq H(x(t), u, \lambda(t), t)
\]
for all time \( t \in [0, T] \) and for all permissible control inputs \( u \in \mathbb{U} \). Here, the trajectory of the Lagrangian multiplier vector \( \lambda \) is the solution to the costate equation and its terminal conditions:
\[
-\dot{\lambda}(t) = H_x (x^*(t), u^*(t), \lambda^*(t), t) = \lambda^T (t) \cdot f_x (x^*(t), u^*(t)) + L_x (x^*(t), u^*(t)) \quad \text{(1)}
\]
\[
\lambda^T (T) = \Psi_x (x(T)) \quad \text{(2)}
\]
If \( x(T) \) is fixed, then these three conditions in (1)-(3) are the necessary conditions for an optimal control.


**- Discrete time PMP and KKT** 

In discrete time setting, the PMP can be viewed as a special case of [Karush–Kuhn–Tucker conditions](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions) (KKT), check out the second reference for more details from Prof. Zac Manchester. Let's first take a look at the optimization problem formulated as follows:

$$ \min_{u_k} \sum_{k=0}^{N-1} L(x_k, u_k) + \Phi(x_N) $$

$$ s.t. \quad x_{k+1} = f(x_k, u_k) $$

Same as before, \\(f(x_k, u_k)\\) defines the system dynamics and \\(\Phi(x_N)\\) is the terminal cost function.

- Formulate the Lagrangian Function:

$$ \mathcal{L} = \sum_{k=0}^{N-1} \left[ L(x_k, u_k) + \lambda_{k+1}^\top \left( f(x_k, u_k) - x_{k+1} \right) \right] + \Phi(x_N) $$

$$ \mathcal{L} = L(x_0, u_0) + \lambda_{1}^\top f(x_k, u_k) + \sum_{k=1}^{N-1} \left[ L(x_k, u_k) + \lambda_{k+1}^\top f(x_k, u_k) - \lambda_{k}^\top x_{k+1}  \right] + \Phi(x_N) - \lambda_{N}^\top x_N $$

- Define Control Hamiltonian:

$$ H_k (x_k, u_k, \lambda_{k+1}) = L(x_k, u_k) + \lambda_{k+1}^\top f(x_k, u_k) $$

The Langrangian function can be then rewritten as:

$$ \mathcal{L} = H_1 (x_1, u_1, \lambda_{2}) + \sum_{k=1}^{N-1} \left[ H_k (x_k, u_k, \lambda_{k+1}) - \lambda_{k}^\top x_k  \right] + \Phi(x_N) - \lambda_{N}^\top x_N$$

Suppose \\(x\\) has \\( n\\) elements (\\(n \times 1 \\) vetor), taking the partial derivatives w.r.t. corresponding variables:

- Partial Derivative with respect to \\( \lambda_{k+1} \\):

$$ x_{k+1} = f(x_k, u_k) \quad (n \times 1) $$

- Partial Derivative with respect to \\( x_k (k < N-1 ) \\): 

$$ \lambda_k = \frac{\partial L(x_k, u_k)}{\partial x_k} + \left( \frac{\partial f(x_k, u_k)}{\partial x_k} \right)^\top \lambda_{k+1} \quad (n \times 1) $$

Here, the term \( -\lambda_k \) appears because \( x_k \) is also present in the term \( \lambda_k^\top \left( f(x_{k-1}, u_{k-1}) - x_k \right) \) from the previous time step \( k - 1 \).


$$ \frac{\partial \mathcal{L}}{\partial x_k} = \frac{\partial L(x_k, u_k)}{\partial x_k} + \lambda_{k+1}^\top \frac{\partial f(x_k, u_k)}{\partial x_k} - \lambda_k $$

- Partial Derivative with respect to \\( x_N\\): 

$$ \lambda_N = \frac{\partial \Phi(x_N)}{\partial x_N} \quad (n \times 1) $$

- **State Equation:**

- **Costate Equation:**

- **Terminal Condition:**

- **Optimality Condition:**
$$ \frac{\partial H_k}{\partial u_k} = 0 \quad (m \times 1) $$

### Partial Derivative of the Running Cost \( L(x_k, u_k) \) with Respect to \( x_k \)

Let's assume that the state vector \( x_k \) has \( n \) elements, so \( x_k = [x_{k1}, x_{k2}, \ldots, x_{kn}]^\top \).

The gradient (partial derivatives) of \( L(x_k, u_k) \) with respect to \( x_k \) is a column vector:

$$
\frac{\partial L(x_k, u_k)}{\partial x_k} = 
\begin{bmatrix}
\frac{\partial L}{\partial x_{k1}} \\
\frac{\partial L}{\partial x_{k2}} \\
\vdots \\
\frac{\partial L}{\partial x_{kn}}
\end{bmatrix}
$$

- Dimension: \( n \times 1 \)

### Jacobian Matrix of the Dynamics Function \( f(x_k, u_k) \) with Respect to \( x_k \)

Assume the dynamics function \( f(x_k, u_k) \) produces an \( n \)-dimensional vector as well. Each component \( f_i \) of \( f \) is a function of the state vector \( x_k \).

The Jacobian matrix of \( f(x_k, u_k) \) with respect to \( x_k \) is given by:

$$
\frac{\partial f(x_k, u_k)}{\partial x_k} = 
\begin{bmatrix}
\frac{\partial f_1}{\partial x_{k1}} & \frac{\partial f_1}{\partial x_{k2}} & \cdots & \frac{\partial f_1}{\partial x_{kn}} \\
\frac{\partial f_2}{\partial x_{k1}} & \frac{\partial f_2}{\partial x_{k2}} & \cdots & \frac{\partial f_2}{\partial x_{kn}} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial f_n}{\partial x_{k1}} & \frac{\partial f_n}{\partial x_{k2}} & \cdots & \frac{\partial f_n}{\partial x_{kn}}
\end{bmatrix}
$$

- Dimension: \( n \times n \)

## Optimization Problem


### Necessary Conditions (PMP)

**State Equation (Primal Feasibility)**:

$$
x_{k+1} = f(x_k, u_k)
$$

**Costate Equation (Dual Feasibility)**:

$$
\lambda_k = \frac{\partial L(x_k, u_k)}{\partial x_k} + \left( \frac{\partial f(x_k, u_k)}{\partial x_k} \right)^\top \lambda_{k+1}
$$

**Optimality Condition (Stationarity)**:

$$ \frac{\partial H_k}{\partial u_k} = 0 \quad \text{where} \quad H_k = L(x_k, u_k) + \lambda_{k+1}^\top f(x_k, u_k) $$

**Terminal Condition**:

$$ \lambda_N = \frac{\partial \Phi(x_N)}{\partial x_N} $$


## Example 2: Constrained Cotinuous LQR

Fixed final state

$$ \min_{x(t), u(t)} \frac{1}{2} \int_{0}^{t_f} \left( x^T(t) Q x(t) + u^T(t) R u(t) \right) dt $$

subject to

$$ \dot{x}(t) = A x(t) + B u(t), \quad x(0) = r_0, \quad x(t_f) = r_f, \quad u \in \mathcal{U} $$

Hamiltonian

$$ H = - \frac{1}{2} x^T Q x - \frac{1}{2} u^T R u + \lambda^T (A x + B u) $$

$$ - \frac{1}{2} u^{*T} R u^* + \lambda^{*T} B u^* \geq - \frac{1}{2} u^T R u + \lambda^{*T} B u, \quad u \in \mathcal{U} $$

or

$$ u^* = \arg\max_{u \in \mathcal{U}} \left[ - \frac{1}{2} u^T R u + \lambda^{*T} B u \right] $$

Scalar case (first-ordered and single-input system)

$$ u^*(t) = \arg\max_{u_{\min} \leq u(t) \leq u_{\max}} \left[ - \frac{1}{2} r u(t)^2 + b \lambda^*(t) u(t) \right]$$

Recall \\( r > 0 \\) (bump not valley)

$$
u^* = 
\begin{cases} 
\frac{b \lambda^*}{r} & \text{if } u_{\min} \leq \frac{b \lambda^*}{r} \leq u_{\max} \\
u_{\min} & \text{if } \frac{b \lambda^*}{r} < u_{\min} \\
u_{\max} & \text{if } \frac{b \lambda^*}{r} > u_{\max}
\end{cases}
$$

$$ u^*(t) = \text{sat}_{u_{\min}}^{u_{\max}} \left( \frac{b \lambda^*(t)}{r} \right) $$

Substitute into the Hamilton canonical equations (state and costate equations)

$$ \dot{x} = a x + b \, \text{sat} \left( \frac{b \lambda^*(t)}{r} \right) $$

$$ \dot{\lambda} = - a \lambda + q x $$

In general

$$ u^* \neq \text{sat}(u_{\text{LQR}}) $$



## Summary
 - PMP provides 

### References
 - [L7.1 Pontryagin's principle of maximum (minimum) and its application to optimal control [YouTube]](https://www.youtube.com/watch?v=Bxc4iy2xUjc&list=PLMLojHoA_QPmRiPotD_TnfdUkglTexuqm&index=16&t=1s)
 - [Optimal Control (CMU 16-745) 2023 Lecture 6: Deterministic Optimal Control Intro [YouTube]](https://www.youtube.com/watch?v=U9zrNwMXktQ&list=PLZnJoM76RM6KugDT9sw5zhAmqKnGeoLRa&index=10) (Deriviation of PMP in discrete time setting, starting at 57 minutes and 15 seconds)
 - [Geomety of the Pontryagin Maximum Principle  [YouTube]](https://www.youtube.com/watch?v=V04N9X3NxYA&t=9s)
 - [Hamiltonian Method of Optimization of Control Systems  [YouTube]](https://www.youtube.com/watch?v=r-fscDKfeUs) (Clear example problem solved using Control Hamiltonian)
 - [Why the Riccati Equation Is important for LQR Control [YouTube]](https://www.youtube.com/watch?v=ZktL3YjTbB4) (Derivation of ARE from another perspective)

