---
title: "From Control Hamiltonian to Algebraic Riccati Equation and Pontryagin's Maximum Principle"
date: 2024-07-16
permalink: /posts/2024/07/16
tags:
  - Algebraic Riccati Equation
  - Linear Qudratic Regulator
  - Calculus of Variations
---
Inspired by the Hamiltonian of classical mechanics, Lev Pontryagin introduced the [_Control Hamiltonian_](https://en.wikipedia.org/wiki/Hamiltonian_(control_theory)) and formulated his celebrated [_Pontragin's Maximum Principle (PMP)_](https://en.wikipedia.org/wiki/Pontryagin%27s_maximum_principle). This blog will first discuss general cases of optimal control problems, including scenarios with both free final time and final states. Then, the derivation of [_Algebraic Riccati Equation (ARE)_](https://en.wikipedia.org/wiki/Algebraic_Riccati_equation) in the context of **_Continuous Linear Qudratic Regulator (LQR)_** from the perspective of the **_Control Hamiltonian_** will be introduced. It will then explain the **_PMP_**, finally followed by the example problem of **_Constrained Continous LQR_**.

## More general senarios of optimal control problems

Consider the following simple robot dynamics (single-integrator model) and the objetive functional aimed to minimize:

$$ J = \frac{1}{2} \int_{0}^{1} (x^2 + u^2) \, dt $$

$$ s.t. \dot{x} = u(t)$$

This is also in [one of the previous blogs](https://lihanlian.github.io/posts/2024/06/30) on Euler-Lagrange Equation, and it's the second example but is a fixed final state and fixed final time problem (\\(x(0) = 0, x(1) = 10,\\)). In this blog, Let's take a look at more general cases including free final state and/or free final time. However, before directly solves the problem, I want to shows the process of derivation common solution strategries for different secaniros using calculus of variations.



**- Fixed final state with free final time**

**- Free final state with fixed final time**

**- Free final state with free final time**

## Continuous LQR and ARE

It turns out that the Algebraic Riccati Equation can be derived using PMP.

$$ J = \frac{1}{2} \int_{0}^{T} (x(t)'Qx(t) + u(t)'Ru(t)) \, dt $$
 
$$ s.t. \dot{x} = Ax(t) + Bu(t) $$

### - Formulate Control Hamiltonian:

$$ H(x, u, \lambda, t) = \frac{1}{2} (x'Qx + u'Ru) + \lambda' (Ax + Bu) $$

### - Construsct co-state Equations:

$$ \dot{\lambda} = -\frac{\partial H}{\partial x} $$

$$ \frac{\partial H}{\partial x} = Qx + A'\lambda $$

$$ \dot{\lambda} = -Qx - A'\lambda $$

### - Obtaining Optimal \\( u \\):

Since we are __NOT__ concerned with the control input constraints here, the optimal control input \\(u\\) can be directly obtained by setting the paritial derivatives to be zero.

$$ \frac{\partial H}{\partial u} = Ru + B'\lambda = 0, \quad  u = -R^{-1}B'\lambda$$

### - Substitute optimal \\( u \\) into state space equation:

$$ \dot{x} = Ax + B(-R^{-1}B'\lambda) = Ax - BR^{-1}B'\lambda $$

### - Riccati Equation:

Suppose \\( \lambda = Px \\), then \\( \dot{\lambda} = \dot{P}x + Px \\), substitute into co-state equation: 

$$ \dot{\lambda} = \dot{P}x + P(Ax - BR^{-1}B'Px) = -Qx - A'Px $$

$$ \dot{P}x + PAx - PBR^{-1}B'Px = -Qx - A'Px $$

$$ \dot{P} + PA + A'P - PBR^{-1}B'P + Q = 0 $$

## Pontryagin's Maximum Principle

**- Continuous time seeting of PMP**

Consider an n-dimensional dynamical system, with state variable \( x \in \mathbb{R}^n \), and control variable \( u \in \mathbb{U} \), where \(\mathbb{U}\) is the set of admissible controls. The evolution of the system is determined by the state and the control, according to the differential equation

$$ \dot{x} = f(x, u).$$

Let the system's initial state be \\( x_0 \\) and let the system's evolution be controlled over the time period with values \\( t \in [0, T] \\). The latter is determined by the following differential equation:
\[
\dot{x} = f(x, u), \quad x(0) = x_0, \quad u(t) \in \mathbb{U}, \quad t \in [0, T].
\]
The control trajectory \( u : [0, T] \to \mathbb{U} \) is to be chosen according to an objective. The objective is a functional \( J \) defined by
\[
J = \Psi(x(T)) + \int_{0}^{T} L(x(t), u(t)) \, dt,
\]
where \( L(x, u) \) can be interpreted as the rate of cost for exerting control \( u \) in state \( x \), and \( \Psi(x) \) can be interpreted as the cost for ending up at state \( x \). The specific choice of \( L \), \( \Psi \) depends on the application.

The constraints on the system dynamics can be adjoined to the Lagrangian \( L \) by introducing time-varying Lagrange multiplier vector \( \lambda \), whose elements are called the costates of the system. This motivates the construction of the Hamiltonian \( H \) defined for all \( t \in [0, T] \) by:
\[
H(x(t), u(t), \lambda(t), t) = \lambda^T(t) \cdot f(x(t), u(t)) + L(x(t), u(t)),
\]
where \( \lambda^T \) is the transpose of \( \lambda \).

Pontryagin's minimum principle states that the optimal state trajectory \( x^* \), optimal control \( u^* \), and corresponding Lagrange multiplier vector \( \lambda^* \) must minimize the Hamiltonian \( H \) so that
\[
H(x^*(t), u^*(t), \lambda^*(t), t) \leq H(x(t), u, \lambda(t), t)
\]
for all time \( t \in [0, T] \) and for all permissible control inputs \( u \in \mathbb{U} \). Here, the trajectory of the Lagrangian multiplier vector \( \lambda \) is the solution to the costate equation and its terminal conditions:
\[
-\dot{\lambda}(t) = H_x (x^*(t), u^*(t), \lambda^*(t), t) = \lambda^T (t) \cdot f_x (x^*(t), u^*(t)) + L_x (x^*(t), u^*(t)) \quad \text{(1)}
\]
\[
\lambda^T (T) = \Psi_x (x(T)) \quad \text{(2)}
\]
If \( x(T) \) is fixed, then these three conditions in (1)-(3) are the necessary conditions for an optimal control.


**- Discrete time of PMP Is a Sepciall case of KKT** 

In discrete time setting, the PMP can be viewed as a special case of [Karush–Kuhn–Tucker conditions](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions) (KKT), check out the second reference for more details from Prof. Zac Manchester.

## Constrained Cotinuous LQR


## Summary
 - PMP provides 

### References
 - [L7.1 Pontryagin's principle of maximum (minimum) and its application to optimal control [YouTube]](https://www.youtube.com/watch?v=Bxc4iy2xUjc&list=PLMLojHoA_QPmRiPotD_TnfdUkglTexuqm&index=16&t=1s)
 - [Optimal Control (CMU 16-745) 2023 Lecture 6: Deterministic Optimal Control Intro [YouTube]](https://www.youtube.com/watch?v=U9zrNwMXktQ&list=PLZnJoM76RM6KugDT9sw5zhAmqKnGeoLRa&index=10) (Deriviation of PMP in discrete time setting, starting from 0:57:15)
 - [Geomety of the Pontryagin Maximum Principle  [YouTube]](https://www.youtube.com/watch?v=V04N9X3NxYA&t=9s)
 - [Hamiltonian Method of Optimization of Control Systems  [YouTube]](https://www.youtube.com/watch?v=r-fscDKfeUs) (Clear example problem solved by using Control Hamiltonian)
 - [Why the Riccati Equation Is important for LQR Control [YouTube]](https://www.youtube.com/watch?v=ZktL3YjTbB4) (Derivation of ARE from another perspective)
<!-- Let \\((X, L)\\) be a real dynamical system with \\(n\\) degrees of freedom. Here \\(X\\) is the [configuration space](https://en.wikipedia.org/wiki/Configuration_space) and \\(L = L(t, q(t), \dot{q}(t))\\) the [Lagrangian](https://en.wikipedia.org/wiki/Lagrangian_mechanics), i.e. a smooth real-valued function such that \\(q(t) \in X\\), and \\(\dot{q}(t)\\) is an \\(n\\)-dimensional "vector of speed". (For those familiar with [differential geometry](https://en.wikipedia.org/wiki/Differential_geometry), \\(X\\) is a [smooth manifold](https://en.wikipedia.org/wiki/Smooth_manifold), and \\(L : \mathbb{R} \times TX \to \mathbb{R}\\), where \\(TX\\) is the [tangent bundle](https://en.wikipedia.org/wiki/Tangent_bundle) of \\(X\\)). -->

<!-- | Derivative                           | Description                                                                 | Ease         |
|--------------------------------------|-----------------------------------------------------------------------------|--------------|
| \\( \frac{\partial L}{\partial z(t_1)} \\) | Gradient of loss with respect to output.                                      | Easy         |
| \\( \frac{dz(t_1)}{d\theta} \\)      | Jacobian of output with respect to params.                                   | Not easy     |
| \\( \lambda(t) \\)                   | Derivative of lambda, a vector, with respect to time.                         | Easy         |
| \\( \lambda(t) \frac{\partial f}{\partial z} \\) | vector-Jacobian Product. Can compute with reverse mode autodiff without explicitly constructing Jacobian \\( \frac{\partial f}{\partial z} \\). | Easy         |
| \\( \frac{dz(t)}{d\theta} \\)        | Jacobian of arbitrary layer with respect to params.                           | Not easy     |
| \\( \lambda(t) \frac{\partial f}{\partial \theta} \\) | vector-Jacobian Product. Can compute with reverse mode autodiff without explicitly constructing Jacobian \\( \frac{\partial f}{\partial \theta} \\). | Easy         |

So we see that (10) requires calculating \\( \frac{dz(t)}{d\theta} \\) at the very last point in time \\( t_1 \\) (output layer) and possibly any general point in time \\( t \\) (arbitrary hidden layer). That is exactly what we're trying to avoid!

Can we get rid of \\( \frac{dz(t)}{d\theta} \\) from (10) by making a judicious choice of \\( \lambda(t) \\)? 🧐 -->
