---
title: 'On Derivation of Hamilton-Jacobi-Bellman Equation and Its Application'
date: 2024-08-15
permalink: /posts/2024/08/15
tags:
  - Optimal Control
  - Dynamic Programming
  - Reinforcement Learning
---
[_Hamilton-Jacobi-Bellman (HJB) equation_](https://en.wikipedia.org/wiki/Hamilton%E2%80%93Jacobi%E2%80%93Bellman_equation) is arguably <span style="color:red">one of THE most important</span> cornerstones of optimal control theory and reinforcement learning. In this blog will delve into the derivation of the **_HJB euqation_**, and deriving the famous **_Algebraic Riccati equation (ARE)_** from this perspective. In the end, I will highlight some of its significance application in various domains of robitcs. By elucidating these fundamental equations, we aim to shed light on their critical roles in reinforcement learning, optimal control, and robotics. 

## Discrete-Time Bellman Equation and Hamilton-Jacobi Equation

## Derivation of HJB equation

## Derivation of ARE using HJB Equation

## Summary

### References
 - [Nonlinear Control: Hamilton Jacobi Bellman (HJB) and Dynamic Programming](https://www.youtube.com/watch?v=-hO-AnFYm6M&list=PLMrJAkhIeNNQe1JXNvaFvURxGY4gE9k74&index=8&t=929s)
 - [EE 564: Lecture 26 (Optimal Control): The Hamilton Jacobi Bellman Approach](https://www.youtube.com/watch?v=kDtcg6U49kY&t=1s)