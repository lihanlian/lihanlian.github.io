---
title: 'Dwell on Differential Dynamic Programming (DDP) and Iterative Linear Quadratic Regulator (iLQR)'
date: 2024-08-10
permalink: /posts/2024/08/10
tags: [Trajectory Optimization, Dynamic Programming, Reinforcement Learning]
---
Algthough optimal control and reinforcement learning appears to be quite different from eacho other, it turns out they are actually closely related. [_Differential Dynamic Programming (DDP)_](https://en.wikipedia.org/wiki/Differential_dynamic_programming) and the **_Iterative Linear Quadratic Regulator (iLQR)_**, two powerful algorithms used in optimal control, are great examples on how model-base reinforcement learning can be related. This blog begins with a discussion on the fundamental principles, including **_Newton's method_**, **_Bellman's Equation_**, and the concept of **_contraction mapping_**. Following this theoretical foundation, later it delves into the specifics of the DDP and iLQR algorithms, illustrating their application through the challenging problem of double pendulum swing-up control.

## Newton's Method and Line Search

## Bellman's Equation and Contraction Mapping

## DDP Algorithms

## iLQR Algorithms

## Example:

## Summary

### References
 - [CS 285: Lecture 10, Part 4 [YouTube]](https://www.youtube.com/watch?v=-hO-AnFYm6M&list=PLMrJAkhIeNNQe1JXNvaFvURxGY4gE9k74&index=8&t=929s) (Part of Deep Reinforcement Learning Open Course at UC Berkeley)
 - [Iterative linear quadratic regulator [YouTube]](https://www.youtube.com/watch?v=ryu0BbE4nb8&list=PLyXDCTF4yPcQ1GozC3vPmrJuN-icTFOW0&index=24)
 - [RL â€” LQR & iLQR Linear Quadratic Regulator [Blog Post]](https://jonathan-hui.medium.com/rl-lqr-ilqr-linear-quadratic-regulator-a5de5104c750)