---
title: 'Dwell on Differential Dynamic Programming (DDP) and Iterative Linear Quadratic Regulator (iLQR)'
date: 2024-08-31
permalink: /posts/2024/08/31
tags: [Trajectory Optimization, Dynamic Programming, Reinforcement Learning]
---
Algthough optimal control and reinforcement learning appears to be quite different from each other, it turns out they are actually closely related. [_Differential Dynamic Programming (DDP)_](https://en.wikipedia.org/wiki/Differential_dynamic_programming) and **_Iterative Linear Quadratic Regulator (iLQR)_**, two powerful algorithms commonly used in trajectory optimizations, are great examples on how model-based reinforcement learning can be related. This blog begins with a discussion on the fundamental principles, including **_Newton's method_** and **_Bellman's Equation_**. Later it delves into the specifics of the DDP and iLQR algorithms, illustrating their application through the classical problem of double pendulum swing-up control.

## Newton's Method and Line Search

   Netwon's Method is an iterative optimization algorithm primarily used for root finding and unconstrained optimization problems. It is a useful numerical approach that uses second-order derivative information when the analytical solutions are impractical. Line search is a technique that used in optimization to find a suitable step size that ensure appropriate update. It is often used in conjunction with gradient-based methods including Newton's Method.

 - ### Newton's Method for Root Finding

 - ### Newton's Method for Optimization

## Bellman's Principle of Optimality 

## iLQR Algorithms

## DDP Algorithms

## Example:

## Summary

### References
 - [CS 285: Lecture 10, Part 4 [YouTube]](https://www.youtube.com/watch?v=-hO-AnFYm6M&list=PLMrJAkhIeNNQe1JXNvaFvURxGY4gE9k74&index=8&t=929s) (Part of Deep Reinforcement Learning Open Course at UC Berkeley)
 - [Optimal Control (CMU 16-745) 2023 Lecture 11: Differential Dynamic Programming](https://www.youtube.com/watch?v=hUf5YhSptLs&list=PLZnJoM76RM6KugDT9sw5zhAmqKnGeoLRa&index=18) (Part of optimal control open course from CMU)
 - Excellent resources from Cornell: [lecture slides](https://www.cs.cornell.edu/courses/cs6756/2022fa/assets/slides_notes/lec6_slides.pdf) & [notes](https://wensun.github.io/CS4789_data/Iterative_LQR-3.pdf)
 - [Iterative linear quadratic regulator [YouTube]](https://www.youtube.com/watch?v=ryu0BbE4nb8&list=PLyXDCTF4yPcQ1GozC3vPmrJuN-icTFOW0&index=24) (Include the connection with Pontryagin's Maximum Principle)
 - [RL â€” LQR & iLQR Linear Quadratic Regulator [Blog Post]](https://jonathan-hui.medium.com/rl-lqr-ilqr-linear-quadratic-regulator-a5de5104c750)