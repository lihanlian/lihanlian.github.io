---
title: "Implementation Details of Cartoon-VAE-Diffusion"
date: 2025-06-30
permalink: /posts/blog8
tags:
  - Generative Models
  - Diffusion Models
  - Computer Vision
---
**Variational Autoencoder (VAE)** learns to compress data into a latent Gaussian space and reconstruct it in a single shot. [**Denoising Diffusion Probabilistic Model (DDPM)**](https://arxiv.org/pdf/2006.11239) tackles the same evidence-lower-bound objective from another direction: it begins with pure noise and iteratively denoise through hundreds of steps, exchanging speed for high-fidelity, stable synthesis. Both frameworks connect random noise to data, yet VAE rely on an explicit **encoder–decoder pair**, whereas DDPM use a learned Markov chain that inverts a forward noising process. This blog traces the progression from VAE to DDPM, clarifying their shared principles, with code examples available at this <i class="fa-brands fa-github"></i> [repository](https://github.com/lihanlian/cartoon-diffusion-model).

## Problem Formulation for Image Generation Model

  We posit that every image $$x \in \mathbb{R}^n$$ is generated by first sampling a low-dimensional latent $$z \in \mathbb{R}^d$$ and then “decoding” it into pixel-space:

  - **Prior on latents:**

    $$
    P_\theta(z)
    $$

    (usually $$\mathcal{N}(0,I)$$, _no_ dependence on $$x$$).

  - **Decoder likelihood** (a Gaussian around a neural-net mean):

    $$
    P_\theta(x \mid z) \;=\; \mathcal{N}\bigl(x;\;G_\theta(z),\;\sigma^2 I\bigr),
    $$

    where $$G_\theta(z)$$ is the deterministic network output (the mean).

    From these we get the **joint**,

    $$
    P_\theta(x,z) \;=\; P_\theta(z)\,P_\theta(x\mid z),
    $$

    and the **marginal** (aka evidence),

    $$
    P_\theta(x) \;=\; \int P_\theta(x,z)\,dz
    \;=\;
    \int P_\theta(z)\,P_\theta(x\mid z)\,dz.
    $$

    - **$$P_\theta(z)$$:** “How we expect latents to be distributed, _before_ seeing any image.”
    - **$$P_\theta(x\mid z)$$:** “If the latent was $$z$$, how likely is image $$x$$?”
    - **$$P_\theta(x,z)$$:** joint chance of drawing $$z$$ then generating $$x$$.
    - **$$P_\theta(x)$$:** overall likelihood of observing image $$x$$ under our model.


## Variational Autoencoders (VAE)

- ### Evidence Lower Bound (ELBO)

- ### Final Objective Function

- ### Code Example

  <figure style="display: block; margin: 0 auto; width: 80%;">
    <img src='/images/blog/blog8/vae_result.png' style="width: 100%;">
    <figcaption style="text-align: center;">VAE sampling result. Trained with z_dim = 512, epochs = 100.</figcaption>
  </figure>

## Diffusion Models

## DDPM

- ### Results

## References
 1. <i class="fab fa-youtube"></i> [Variational Autoencoder - Model, ELBO, loss function and maths explained easily!](https://www.youtube.com/watch?v=iwEzwTTalbg) 
 2. <i class="fab fa-youtube"></i> [Understanding Variational Autoencoders (VAEs)](https://www.youtube.com/watch?v=HBYQvKlaE0A) 
 3. <i class="fab fa-youtube"></i> [The Breakthrough Behind Modern AI Image Generators - Diffusion Models Part 1](https://www.youtube.com/watch?v=1pgiu--4W3I&t=1s) 
 4. <i class="fa-solid fa-book-open"></i> [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239) (DDPM Paper) 
 5. <i class="fa-solid fa-book-open"></i> [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502) (DDIM Paper) 
 6. <i class="fab fa-youtube"></i> [Diffusion Model Paper Explanation](https://www.youtube.com/watch?v=HoKDTa5jHvg), [PyTorch Implementation Walk Through](https://www.youtube.com/watch?v=TBCRlnwJtZU&t=874s) and corresponding <i class="fa-brands fa-github"></i> [github repo](https://github.com/dome272/Diffusion-Models-pytorch)
 7. <i class="fa-brands fa-github"></i> [diffusion-DDPM-pytorch](https://github.com/Alokia/diffusion-DDPM-pytorch) & [diffusion-DDIM-pytorch](https://github.com/Alokia/diffusion-DDIM-pytorch)
 8. <i class="fab fa-youtube"></i> [An Optimal Control Perspective on Diffusion-Based Generative Modeling](https://www.youtube.com/watch?v=wQpQg1xIlBA&list=LL&index=3&t=2299s) & [SDE/ODE Interpretation of Diffusion Model](https://www.youtube.com/watch?v=Ro4v4z8YAsk&list=LL&index=3)
